{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Federico6419/MachineLearningProject/blob/main/MachineLearningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jDBR7kyywx2"
      },
      "source": [
        "## Install libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A3otcPC9xYL",
        "outputId": "499fc61f-22b8-4026-d501-03c7a7d86cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.1.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373126 sha256=2dc3e69b1e7e109fd5ab90bd45e21793b3db4b970e4da91a2ba7e53d1a7faa59\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n",
            "Collecting gym-notebook-wrapper\n",
            "  Downloading gym_notebook_wrapper-1.3.3-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (0.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (3.7.1)\n",
            "Collecting pyvirtualdisplay (from gym-notebook-wrapper)\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (7.34.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym->gym-notebook-wrapper) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->gym-notebook-wrapper) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->gym-notebook-wrapper) (0.0.8)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->gym-notebook-wrapper)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (4.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (2.8.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (0.4.9)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->gym-notebook-wrapper) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->gym-notebook-wrapper) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->gym-notebook-wrapper) (0.2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->gym-notebook-wrapper) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (2023.7.22)\n",
            "Installing collected packages: pyvirtualdisplay, jedi, gym-notebook-wrapper\n",
            "Successfully installed gym-notebook-wrapper-1.3.3 jedi-0.19.1 pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 7,814 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.2 [28.1 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.2 [864 kB]\n",
            "Fetched 7,814 kB in 1s (5,435 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.2_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.2_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Collecting xvfbwrapper\n",
            "  Downloading xvfbwrapper-0.2.9.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: xvfbwrapper\n",
            "  Building wheel for xvfbwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xvfbwrapper: filename=xvfbwrapper-0.2.9-py3-none-any.whl size=5009 sha256=8529ea2f0f5ee8894f8fade5cc033416438a1fbc19f193b97f2dc66a47ce0771\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/10/7d/2b7fdffccf837f7d5425931575fbee9caebe2c190931f9058b\n",
            "Successfully built xvfbwrapper\n",
            "Installing collected packages: xvfbwrapper\n",
            "Successfully installed xvfbwrapper-0.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install swig     #This solves the errori in the installation of gymnasium[box2d]\n",
        "!pip install gymnasium[box2d]\n",
        "!pip install gym-notebook-wrapper   #This installs Gym-Notebook-Wrapper, that provides small wrappers for running and rendering OpenAI Gym\n",
        "\n",
        "#To solve the xvfb missing file problem\n",
        "!sudo apt-get install xvfb\n",
        "!pip install xvfbwrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lCpyHIx0K0w"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IW5i1FfF0PeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e3bca3-02f5-40ff-b58f-9229194e1549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MachineLearningProject'...\n",
            "remote: Enumerating objects: 258, done.\u001b[K\n",
            "remote: Counting objects: 100% (128/128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 258 (delta 81), reused 4 (delta 4), pack-reused 130\u001b[K\n",
            "Receiving objects: 100% (258/258), 1000.07 KiB | 7.52 MiB/s, done.\n",
            "Resolving deltas: 100% (153/153), done.\n",
            "/content/MachineLearningProject\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Federico6419/MachineLearningProject          #It clones my github repository\n",
        "%cd MachineLearningProject\n",
        "\n",
        "import gymnasium as gym\n",
        "import gnwrapper\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import config\n",
        "from model import Model\n",
        "from collections import deque\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F"
      ],
      "metadata": {
        "id": "MKJKM9g2pV6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive                                   #This is commented because we used to save or load our results using our Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "episode_reward = 0\n",
        "tot_negative_reward = 0\n",
        "time_frame_counter = 1\n",
        "buffer = deque([], config.BUFFER_SIZE)             #Initialize the Queue that contains the past experience\n",
        "epsilon = config.MAX_EPSILON\n",
        "if(config.LOAD_CHECKPOINT):\n",
        "    epsilon = config.LOADED_EPSILON\n",
        "\n",
        "alpha = config.ALPHA\n",
        "decay = config.EPSILON_DECAY\n",
        "\n",
        "#For the plotting\n",
        "cum_reward_table = np.zeros(config.NUM_EPISODES)\n",
        "cum_reward_nn = np.zeros(config.NUM_EPISODES)\n",
        "\n",
        "#Initialize the Model\n",
        "model = Model().to(config.DEVICE)\n",
        "\n",
        "#Initialize the Target Model\n",
        "target_model = Model().to(config.DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.LR)\n",
        "optimizer_target = optim.Adam(target_model.parameters(), lr=config.LR)\n",
        "\n",
        "if(config.LOAD_CHECKPOINT):\n",
        "    config.load_model(config.LOAD_CHECKPOINT_FOLDER,model,optimizer)\n",
        "    config.load_model(config.LOAD_CHECKPOINT_FOLDER,target_model,optimizer_target)\n",
        "\n",
        "#huber_loss=nn.HuberLoss(delta=1.0)\n",
        "mean_squared_error = torch.nn.MSELoss()\n",
        "\n",
        "#Define the Action Space\n",
        "action_space = [\n",
        "                (-1, 1, 0.2), (0, 1, 0.2), (1, 1, 0.2),\n",
        "                (-1, 1,   0), (0, 1,   0), (1, 1,   0),               #(Steering Wheel, Gas, Break)\n",
        "                (-1, 0, 0.2), (0, 0, 0.2), (1, 0, 0.2),               #Range -1~1 0~1 0~1\n",
        "                (-1, 0,   0), (0, 0,   0), (1, 0,   0)\n",
        "              ]\n",
        "\n",
        "#Define the policy to know how chose the action\n",
        "#Q-Table\n",
        "def select_action(state, epsilon):\n",
        "    rv = random.uniform(0, 1)\n",
        "    if rv < epsilon:\n",
        "        return env.action_space.sample()\n",
        "    else:\n",
        "        return np.argmax(Q[state])\n",
        "\n",
        "#Neural Network\n",
        "def select_action_nn(state, epsilon):\n",
        "    rv = random.uniform(0, 1)\n",
        "    if rv < epsilon:\n",
        "        return action_space[random.randrange(len(action_space))]          #We sample a random action\n",
        "\n",
        "    else:\n",
        "        prediction = model(torch.from_numpy(state.astype('float32')).to(config.DEVICE)).detach().cpu().numpy()\n",
        "        action = action_space[np.argmax(prediction)]              #Select the action with the maximum predicted Q-Value\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "## update the epsilon value along the iteration until converges to MIN_EPSILON\n",
        "def update_epsilon(epsilon):\n",
        "    epsilon -= epsilon/100 # reduce epsilon by 1/100\n",
        "    if epsilon<=config.MIN_EPSILON:\n",
        "        return config.MIN_EPSILON\n",
        "    else:\n",
        "        return epsilon\n",
        "\n",
        "## update the epsilon every episode by epsilon decay variable\n",
        "def update_epsilon_nn(epsilon):\n",
        "    epsilon *= decay\n",
        "    if epsilon<=config.MIN_EPSILON:\n",
        "        return config.MIN_EPSILON\n",
        "    else:\n",
        "        return epsilon\n",
        "\n",
        "\n",
        "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
        "\n",
        "\n",
        "if(config.USE_QTABLE):\n",
        "    # define the Q table\n",
        "    #Q = np.zeros([27684, env.action_space.n]) # little discretization\n",
        "    Q = np.zeros([19051200, env.action_space.n]) #big discretization\n",
        "\n",
        "###see the limit of the values of the box observation space\n",
        "#print(env.observation_space.high)\n",
        "#print(env.observation_space.low)\n",
        "\n",
        "###see in more detail the action space and the observation space\n",
        "#print(env.action_space)\n",
        "#print(env.observation_space)\n",
        "\n",
        "\n",
        "if(config.USE_QTABLE): # use a q table to reach the goal\n",
        "    for i in range(config.NUM_EPISODES):\n",
        "        observation, info = env.reset()# use seed to have same initial state\n",
        "        #state = config.discretize(observation)\n",
        "        state = config.big_discretize(observation)\n",
        "\n",
        "        for j in range(500):\n",
        "            action = select_action(state,epsilon)\n",
        "            obv, reward, done, truncated, info = env.step(action)\n",
        "            #next_state = config.discretize(obv)\n",
        "            next_state = config.big_discretize(obv)\n",
        "\n",
        "            next_max = np.max(Q[next_state])\n",
        "\n",
        "            Q[state,action] += alpha*(reward+config.GAMMA*next_max-Q[state,action])\n",
        "            state = next_state\n",
        "\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done or truncated:\n",
        "                break\n",
        "\n",
        "        print(\"episode: \", i)\n",
        "        print(\"episode cumulative reward : \", episode_reward)\n",
        "        print(\"epsilon: \",epsilon)\n",
        "        epsilon = update_epsilon(epsilon)\n",
        "        cum_reward_table[i]=episode_reward\n",
        "        episode_reward = 0 #reset the total reward each episode\n",
        "\n",
        "    #save the q table for testing\n",
        "    #np.savetxt('q_table.csv', Q, delimiter=','fmt='%f18')\n",
        "    #np.savetxt('q_table_little_discretization2000.csv', Q, delimiter=',') # full precision\n",
        "    np.savetxt('q_table_big_discretization1000.csv', Q, delimiter=',') # full precision\n",
        "\n",
        "else:             #Use a Neural Network to approximate the Q Function\n",
        "    for i in range(config.NUM_EPISODES):\n",
        "        state, info = env.reset()               #The state is a 96x96 Matrix, that contains elements composed by 3 Colours RGB\n",
        "        state = cv2.cvtColor(state, cv2.COLOR_BGR2GRAY)           #Convert the state into a Grayscale Image, that is a Matrix 96x96 composed by Integer values\n",
        "        #state = state.astype(float)\n",
        "        #state /= 255.0\n",
        "\n",
        "        frames_queue = deque([state]*3, maxlen = 3)\n",
        "\n",
        "        done = False\n",
        "\n",
        "        while(True):\n",
        "\n",
        "            current_frame = np.array(frames_queue)\n",
        "\n",
        "            action = select_action_nn(current_frame, epsilon)                      #The Action is composed by 3 Values, that are the steering, gas and breaking\n",
        "\n",
        "            rew = 0\n",
        "            #Skip Frames\n",
        "            for tot in range(3):\n",
        "                next_state, reward, done, truncated, info = env.step(action)\n",
        "                rew += reward\n",
        "                if done or truncated:\n",
        "                    break\n",
        "\n",
        "            # If continually getting negative reward 10 times after the tolerance steps, terminate this episode\n",
        "            tot_negative_reward = tot_negative_reward + 1 if time_frame_counter > 100 and reward < 0 else 0\n",
        "\n",
        "\n",
        "            # Extra bonus for the model if it uses full gas\n",
        "            if action[1] == 1 and action[2] == 0:\n",
        "                rew *= 1.5\n",
        "\n",
        "            episode_reward += rew\n",
        "\n",
        "            next_state = cv2.cvtColor(next_state, cv2.COLOR_BGR2GRAY)\n",
        "            #Add normalization?\n",
        "\n",
        "            frames_queue.append(next_state)\n",
        "            next_frame = np.array(frames_queue)\n",
        "\n",
        "            #Remove the oldest item if the queue is full, in a way such that we can add a new one\n",
        "            if len(buffer)>=config.BUFFER_SIZE:\n",
        "                buffer.popleft()               #We dequeue the oldest item\n",
        "\n",
        "            #buffer.append([*state,action,reward,*next_state,done])\n",
        "            buffer.append((current_frame, action_space.index(action), reward, next_frame, done))\n",
        "\n",
        "            if done or truncated:    # or tot_negative_reward > 25 or episode_reward < 0:\n",
        "                epsilon = update_epsilon_nn(epsilon)\n",
        "                print(\"episode \", i)\n",
        "                print(\"episode cumulative reward: \", episode_reward)\n",
        "                print(\"current epsilon: \", epsilon)\n",
        "                print(\"#---------------------------------------------#\")\n",
        "                break\n",
        "\n",
        "            #Let's train the Neural Network every 4 actions and if the buffer has at least BATCH_SIZE elements\n",
        "            #if((len(buffer) >= config.BATCH_SIZE) and ((j+1) % 4 == 0)):\n",
        "            if(len(buffer) >= config.BATCH_SIZE):\n",
        "                batch = random.sample(buffer, config.BATCH_SIZE)\n",
        "\n",
        "                for current_frame, action, reward, next_frame, done in batch:\n",
        "\n",
        "                    #VECCHIO MODO\n",
        "                    # Find next best action using model network\n",
        "                    #next_frame = torch.from_numpy(next_frame.astype('float32')).to(config.DEVICE)\n",
        "                    #predictions_next = model(next_frame).detach().cpu().numpy()\n",
        "                    #current_frame = torch.from_numpy(current_frame.astype('float32')).to(config.DEVICE)\n",
        "                    #predictions_next = model(current_frame).detach().cpu().numpy()\n",
        "\n",
        "                    #next_frame = torch.from_numpy(next_frame.astype('float32')).to(config.DEVICE)\n",
        "                    #t = target_model(next_frame)\n",
        "                    #predictions_next[action] = reward + config.GAMMA * max(t)\n",
        "\n",
        "                    #compute the predicted value of the model(output)\n",
        "                    #output = model(current_frame)\n",
        "                    #output =  output[..., np.newaxis]\n",
        "                    #predictions_next =  predictions_next[..., np.newaxis]\n",
        "                    #predictions_next = torch.from_numpy(predictions_next).to(config.DEVICE)\n",
        "                    #loss = huber_loss(output, predictions_next)\n",
        "                    #loss = mean_squared_error(output, predictions_next)\n",
        "\n",
        "                    #NUOVO MODO\n",
        "                    if(done):\n",
        "                        target = reward\n",
        "                    else:\n",
        "                        next_frame = torch.from_numpy(next_frame.astype('float32')).to(config.DEVICE)\n",
        "                        next_frame = target_model(next_frame)\n",
        "                        target = reward + config.GAMMA * max(next_frame)\n",
        "\n",
        "                    current_frame = torch.from_numpy(current_frame.astype('float32')).to(config.DEVICE)\n",
        "                    output = model(current_frame)\n",
        "\n",
        "                    loss = mean_squared_error(output[action], target)\n",
        "\n",
        "                    #Train network\n",
        "                    optimizer.zero_grad()#clear existing gradient\n",
        "                    loss.backward() #backpropagate the error\n",
        "                    optimizer.step() # update weights\n",
        "\n",
        "            time_frame_counter += 1\n",
        "\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            #save the weight of the network\n",
        "            config.save_model(model,optimizer,i+1)\n",
        "            torch.save({\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "            }, \"../drive/MyDrive/Checkpoint\")\n",
        "            print(\"Save weigths in: \"+ config.CHECKPOINT_FOLDER)\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            #update weights of target network every 10 actions\n",
        "            print(\"Target network updated\")\n",
        "            config.load_model(config.CHECKPOINT_FOLDER,target_model,optimizer_target)\n",
        "\n",
        "\n",
        "        cum_reward_nn[i]=episode_reward\n",
        "        episode_reward = 0\n",
        "        tot_negative_reward = 1\n",
        "        time_frame_counter = 1\n",
        "\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OTI2zOGcpXiu",
        "outputId": "e8e2ac40-a3d8-4526-ba46-576987bcdd30"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "OUTPUT\n",
            "tensor(20.4447, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.9236, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.1355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(28.5717, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.4840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.1831, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.3617, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.8068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1981, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.4011, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(26.9081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2430, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.9375, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0461, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.1960, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.2644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.0901, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.9083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(28.3806, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.4090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.0575, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.1964, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.3693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(3.3382, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.3028, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.8356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.5323, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(22.5543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.0444, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.8230, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.5433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0782, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.4448, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(22.7871, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(24.0990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.7209, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.5143, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.8757, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.5860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0839, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.0096, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.9018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.6122, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.8127, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.2743, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.3103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.7768, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(28.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1657, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(28.6706, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.5612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.7933, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.3265, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.9400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1494, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.9488, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.2343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.9397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.4896, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.9687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2296, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.3389, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0395, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.3463, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.3211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(24.3431, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(21.7577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(6.6844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.7821, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.1998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.3390, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(18.8246, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.7997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.9508, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(28.1622, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.6979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.3582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.6549, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.0726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1745, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.4930, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(21.2338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0672, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(18.5810, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.4353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(3.4384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(23.1890, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(25.4493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(5.1089, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.7968, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.4554, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.5397, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.5324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(5.2782e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.4638, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(21.0894, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.3914, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.4245, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0860, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(25.8425, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(22.6995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(9.8786, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.5189, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(30.1269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.3697, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(26.9847, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(23.9330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(9.3127, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.8012, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.6052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0384, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(23.2691, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(18.2970, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(23.3049, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(24.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.9595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.2838, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.0928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.4184, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.5232, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(6.1603e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.2004, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2442, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.8698, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.4628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1656, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.3320, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(26.6274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.4964, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.5756, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.5762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.3058, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0780, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.6421, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2424, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.5409, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(28.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(50.5043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.0920, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.2429, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0588, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.8171, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.6849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(28.8954, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.5174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.3869, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.0122, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.8034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.2450, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.6019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.6999, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(32.4958, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.9228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(6.6204, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.3393, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.8147, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.5789, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5824, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.9931, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.4651, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.2644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.4417, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(26.7386, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.6528, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.7161, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.5860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.2771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(22.2042, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.2097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.3560, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.9018, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.7504, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1541, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.3428, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.6849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.7487, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(22.9924, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(21.7577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.5245, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(26.5781, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.9228, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(11.1868, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.4006, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2898, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(30.4244, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(30.1269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.2670, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.7997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2837, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.0863, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.1361, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(18.8482, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.6052, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.5731, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.3772, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.5823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(31.1835, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.5324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.7262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(26.1463, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(23.9330, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(4.8987, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(22.1299, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(22.5543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1801, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.0729, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.3693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0879, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(18.5759, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.0928, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.3010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(18.9966, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.0296, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.0670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.8404, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.6738, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.8306, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.9696, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.2975, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.4166, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(21.2338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.6678, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(28.9346, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.6979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.5826, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.8882, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.4090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2296, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.0467, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.2031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.5805, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.4716, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.4403, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.9593, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.9687, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(8.8385e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.0264, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(28.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.7099, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.2424, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1813, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.5582, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.7072, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.7004, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.2603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.4365, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.8761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.7885, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.9400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0230, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(32.8130, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(28.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(17.3516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.1456, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.5433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.3627, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(25.3643, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(26.6274, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.5955, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.4427, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.6019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0253, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.9306, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.6124, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.6664, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.5174, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(3.4263, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.6641, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.0858, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.7531, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.8356, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.1719, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(22.5346, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(24.0990, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.4473, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.7886, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1498, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1305, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.6510, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.4628, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.6590, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(23.8059, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(24.2845, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2291, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.8443, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.1998, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.4153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.6398, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7582, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.1111, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.2774e-05, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(30.2889, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.4840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(7.8676, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.1169, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.0726, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.0906, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.7771, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5824, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0379, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.3013, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.2343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(25.6788, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(22.6995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(8.8763, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.8495, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.9083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.9023, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.4353, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2841, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(28.1009, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.5612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.1324, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.0587, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.8068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.5596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(23.7582, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(25.4493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.8599, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.6763, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.6527, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.2200, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(26.9081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0973, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.4805, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.5860, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.8002, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.1386, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(28.6475, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2411, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.5139, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.5612, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(26.9762, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(26.9081, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.0569, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.9400, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.5214, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7173, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.6466, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.3067, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.9390, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1352, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.7610, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.9893, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0521, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.9443, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.9922, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.2367, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.5324, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0874, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.8839, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0671, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.8623, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1522, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0840, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.5261, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7177, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0367, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(22.6262, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.5466, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(24.2101, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.5247, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(21.6596, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.2879, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.6369, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(21.7577, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.2562, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.5531, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.8391, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.3233, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.4854, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0263, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(25.7663, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(25.4493, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.1350, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.5433, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(2.5332, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(30.7173, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(29.6979, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.0392, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.4881, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.6849, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0387, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(28.8368, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.4840, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.8300, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(22.4750, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(21.2338, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.5406, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.3457, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5310, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0343, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.0187, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.6019, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1738, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(21.2065, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.9083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0889, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.9074, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.7997, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.6047, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.8165, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0449, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(23.3028, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(22.5543, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.5602, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(27.5960, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(27.3693, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0514, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.9550, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.2644, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0958, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.7030, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.2343, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.2197, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(26.9184, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(28.1838, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(1.6014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.3395, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5005, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0259, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.2828, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7131, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1852, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.4088, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.7062, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0885, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(24.9390, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(22.6995, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(5.0153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.0383, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(19.8068, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(29.9267, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(30.1269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.0401, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(20.1386, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.5852, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1994, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n",
            "OUTPUT\n",
            "tensor(19.7431, device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "###############\n",
            "TARGET\n",
            "tensor(20.1402, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "\n",
            "###############\n",
            "LOSS\n",
            "tensor(0.1577, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-468b60a6d423>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    236\u001b[0m                     \u001b[0;31m#Train network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#clear existing gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#backpropagate the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCZDvbZaAKye"
      },
      "source": [
        "## Example"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}