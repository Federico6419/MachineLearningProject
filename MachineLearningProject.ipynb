{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Federico6419/MachineLearningProject/blob/main/MachineLearningProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jDBR7kyywx2"
      },
      "source": [
        "## Install libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A3otcPC9xYL",
        "outputId": "f9eef54d-d6da-4fd6-f834-27ea25c76fd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/953.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/953.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.5.2)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.1.1)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp310-cp310-linux_x86_64.whl size=2373076 sha256=aad07445dea66bf8cb47afab555a3bc756e030ad2c94b097ccd51310a2a72b6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/8f/6a/eaaadf056fba10a98d986f6dce954e6201ba3126926fc5ad9e\n",
            "Successfully built box2d-py\n",
            "Installing collected packages: box2d-py\n",
            "Successfully installed box2d-py-2.3.5\n",
            "Collecting gym-notebook-wrapper\n",
            "  Downloading gym_notebook_wrapper-1.3.3-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (0.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (3.7.1)\n",
            "Collecting pyvirtualdisplay (from gym-notebook-wrapper)\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (7.34.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from gym-notebook-wrapper) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym->gym-notebook-wrapper) (1.23.5)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym->gym-notebook-wrapper) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym->gym-notebook-wrapper) (0.0.8)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->gym-notebook-wrapper)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->gym-notebook-wrapper) (4.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gym-notebook-wrapper) (2.8.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->gym-notebook-wrapper) (0.4.9)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->gym-notebook-wrapper) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->gym-notebook-wrapper) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->gym-notebook-wrapper) (0.2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->gym-notebook-wrapper) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->gym-notebook-wrapper) (2023.7.22)\n",
            "Installing collected packages: pyvirtualdisplay, jedi, gym-notebook-wrapper\n",
            "Successfully installed gym-notebook-wrapper-1.3.3 jedi-0.19.1 pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 7,812 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Err:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.1\n",
            "  404  Not Found [IP: 91.189.91.81 80]\n",
            "Err:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.1\n",
            "  404  Not Found [IP: 91.189.91.81 80]\n",
            "Fetched 6,922 kB in 3s (2,310 kB/s)\n",
            "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/x/xorg-server/xserver-common_21.1.4-2ubuntu1.7%7e22.04.1_all.deb  404  Not Found [IP: 91.189.91.81 80]\n",
            "E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/universe/x/xorg-server/xvfb_21.1.4-2ubuntu1.7%7e22.04.1_amd64.deb  404  Not Found [IP: 91.189.91.81 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n",
            "Collecting xvfbwrapper\n",
            "  Downloading xvfbwrapper-0.2.9.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: xvfbwrapper\n",
            "  Building wheel for xvfbwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for xvfbwrapper: filename=xvfbwrapper-0.2.9-py3-none-any.whl size=5009 sha256=fcdbca39dcd16c9f1c31fbdff68dee26fc523ad8d1ad131d3ecd534c450787f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/10/7d/2b7fdffccf837f7d5425931575fbee9caebe2c190931f9058b\n",
            "Successfully built xvfbwrapper\n",
            "Installing collected packages: xvfbwrapper\n",
            "Successfully installed xvfbwrapper-0.2.9\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install swig     #This solves the errori in the installation of gymnasium[box2d]\n",
        "!pip install gymnasium[box2d]\n",
        "!pip install gym-notebook-wrapper   #This installs Gym-Notebook-Wrapper, that provides small wrappers for running and rendering OpenAI Gym\n",
        "\n",
        "#To solve the xvfb missing file problem\n",
        "!sudo apt-get install xvfb\n",
        "!pip install xvfbwrapper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lCpyHIx0K0w"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IW5i1FfF0PeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fd5ef1c-cafc-405c-df6e-a391847872cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MachineLearningProject'...\n",
            "remote: Enumerating objects: 226, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 226 (delta 62), reused 4 (delta 4), pack-reused 130\u001b[K\n",
            "Receiving objects: 100% (226/226), 132.98 KiB | 7.39 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n",
            "/content/MachineLearningProject\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Federico6419/MachineLearningProject          #It clones my github repository\n",
        "%cd MachineLearningProject\n",
        "\n",
        "import gymnasium as gym\n",
        "import gnwrapper\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.utils import save_image\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "import config\n",
        "from model import Model\n",
        "from collections import deque\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# F"
      ],
      "metadata": {
        "id": "MKJKM9g2pV6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive                                   #This is commented because we used to save or load our results using our Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "episode_reward = 0\n",
        "tot_negative_reward = 0\n",
        "time_frame_counter = 1\n",
        "buffer = deque([], config.BUFFER_SIZE)             #Initialize the Queue that contains the past experience\n",
        "epsilon = config.MAX_EPSILON\n",
        "alpha = config.ALPHA\n",
        "decay = config.EPSILON_DECAY\n",
        "\n",
        "#For the plotting\n",
        "cum_reward_table = np.zeros(config.NUM_EPISODES)\n",
        "cum_reward_nn = np.zeros(config.NUM_EPISODES)\n",
        "\n",
        "#Initialize the Model\n",
        "model = Model().to(config.DEVICE)\n",
        "\n",
        "#Initialize the Target Model\n",
        "target_model = Model().to(config.DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.LR)\n",
        "optimizer_target = optim.Adam(target_model.parameters(), lr=config.LR)\n",
        "\n",
        "if(config.LOAD_MODEL):\n",
        "    config.load_model(config.LOAD_CHECKPOINT_FOLDER,model,optimizer)\n",
        "    config.load_model(config.LOAD_CHECKPOINT_FOLDER,target_model,optimizer_target)\n",
        "\n",
        "#huber_loss=nn.HuberLoss(delta=1.0)\n",
        "mean_squared_error = torch.nn.MSELoss()\n",
        "\n",
        "#Define the Action Space\n",
        "action_space = [\n",
        "                (-1, 1, 0.2), (0, 1, 0.2), (1, 1, 0.2),\n",
        "                (-1, 1,   0), (0, 1,   0), (1, 1,   0),               #(Steering Wheel, Gas, Break)\n",
        "                (-1, 0, 0.2), (0, 0, 0.2), (1, 0, 0.2),               #Range -1~1 0~1 0~1\n",
        "                (-1, 0,   0), (0, 0,   0), (1, 0,   0)\n",
        "              ]\n",
        "\n",
        "#Define the policy to know how chose the action\n",
        "#Q-Table\n",
        "def select_action(state, epsilon):\n",
        "    rv = random.uniform(0, 1)\n",
        "    if rv < epsilon:\n",
        "        return env.action_space.sample()\n",
        "    else:\n",
        "        return np.argmax(Q[state])\n",
        "\n",
        "#Neural Network\n",
        "def select_action_nn(state, epsilon):\n",
        "    rv = random.uniform(0, 1)\n",
        "    if rv < epsilon:\n",
        "        return action_space[random.randrange(len(action_space))]          #We sample a random action\n",
        "\n",
        "    else:\n",
        "        prediction = model(torch.from_numpy(state.astype('float32')).to(config.DEVICE)).detach().cpu().numpy()\n",
        "        action = action_space[np.argmax(prediction)]              #Select the action with the maximum predicted Q-Value\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "## update the epsilon value along the iteration until converges to MIN_EPSILON\n",
        "def update_epsilon(epsilon):\n",
        "    epsilon -= epsilon/100 # reduce epsilon by 1/100\n",
        "    if epsilon<=config.MIN_EPSILON:\n",
        "        return config.MIN_EPSILON\n",
        "    else:\n",
        "        return epsilon\n",
        "\n",
        "## update the epsilon every episode by epsilon decay variable\n",
        "def update_epsilon_nn(epsilon):\n",
        "    epsilon *= decay\n",
        "    if epsilon<=config.MIN_EPSILON:\n",
        "        return config.MIN_EPSILON\n",
        "    else:\n",
        "        return epsilon\n",
        "\n",
        "\n",
        "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
        "\n",
        "\n",
        "if(config.USE_QTABLE):\n",
        "    # define the Q table\n",
        "    #Q = np.zeros([27684, env.action_space.n]) # little discretization\n",
        "    Q = np.zeros([19051200, env.action_space.n]) #big discretization\n",
        "\n",
        "###see the limit of the values of the box observation space\n",
        "#print(env.observation_space.high)\n",
        "#print(env.observation_space.low)\n",
        "\n",
        "###see in more detail the action space and the observation space\n",
        "#print(env.action_space)\n",
        "#print(env.observation_space)\n",
        "\n",
        "\n",
        "if(config.USE_QTABLE): # use a q table to reach the goal\n",
        "    for i in range(config.NUM_EPISODES):\n",
        "        observation, info = env.reset()# use seed to have same initial state\n",
        "        #state = config.discretize(observation)\n",
        "        state = config.big_discretize(observation)\n",
        "\n",
        "        for j in range(500):\n",
        "            action = select_action(state,epsilon)\n",
        "            obv, reward, done, truncated, info = env.step(action)\n",
        "            #next_state = config.discretize(obv)\n",
        "            next_state = config.big_discretize(obv)\n",
        "\n",
        "            next_max = np.max(Q[next_state])\n",
        "\n",
        "            Q[state,action] += alpha*(reward+config.GAMMA*next_max-Q[state,action])\n",
        "            state = next_state\n",
        "\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done or truncated:\n",
        "                break\n",
        "\n",
        "        print(\"episode: \", i)\n",
        "        print(\"episode cumulative reward : \", episode_reward)\n",
        "        print(\"epsilon: \",epsilon)\n",
        "        epsilon = update_epsilon(epsilon)\n",
        "        cum_reward_table[i]=episode_reward\n",
        "        episode_reward = 0 #reset the total reward each episode\n",
        "\n",
        "    #save the q table for testing\n",
        "    #np.savetxt('q_table.csv', Q, delimiter=','fmt='%f18')\n",
        "    #np.savetxt('q_table_little_discretization2000.csv', Q, delimiter=',') # full precision\n",
        "    np.savetxt('q_table_big_discretization1000.csv', Q, delimiter=',') # full precision\n",
        "\n",
        "else:             #Use a Neural Network to approximate the Q Function\n",
        "    for i in range(config.NUM_EPISODES):\n",
        "        state, info = env.reset()               #The state is a 96x96 Matrix, that contains elements composed by 3 Colours RGB\n",
        "        state = cv2.cvtColor(state, cv2.COLOR_BGR2GRAY)           #Convert the state into a Grayscale Image, that is a Matrix 96x96 composed by Integer values\n",
        "        #state = state.astype(float)\n",
        "        #state /= 255.0\n",
        "\n",
        "        frames_queue = deque([state]*3, maxlen = 3)\n",
        "\n",
        "        done = False\n",
        "\n",
        "        while(True):\n",
        "\n",
        "            current_frame = np.array(frames_queue)\n",
        "\n",
        "            action = select_action_nn(current_frame, epsilon)                      #The Action is composed by 3 Values, that are the steering, gas and breaking\n",
        "\n",
        "            rew = 0\n",
        "            #Skip Frames\n",
        "            for tot in range(3):\n",
        "                next_state, reward, done, truncated, info = env.step(action)\n",
        "                rew += reward\n",
        "                if done or truncated:\n",
        "                    break\n",
        "\n",
        "            # If continually getting negative reward 10 times after the tolerance steps, terminate this episode\n",
        "            tot_negative_reward = tot_negative_reward + 1 if time_frame_counter > 100 and reward < 0 else 0\n",
        "\n",
        "\n",
        "            # Extra bonus for the model if it uses full gas\n",
        "            if action[1] == 1 and action[2] == 0:\n",
        "                rew *= 1.5\n",
        "\n",
        "            episode_reward += rew\n",
        "\n",
        "            next_state = cv2.cvtColor(next_state, cv2.COLOR_BGR2GRAY)\n",
        "            #Add normalization?\n",
        "\n",
        "            frames_queue.append(next_state)\n",
        "            next_frame = np.array(frames_queue)\n",
        "\n",
        "            #Remove the oldest item if the queue is full, in a way such that we can add a new one\n",
        "            if len(buffer)>=config.BUFFER_SIZE:\n",
        "                buffer.popleft()               #We dequeue the oldest item\n",
        "\n",
        "            #buffer.append([*state,action,reward,*next_state,done])\n",
        "            buffer.append((current_frame, action_space.index(action), reward, next_frame, done))\n",
        "\n",
        "            if done or truncated or tot_negative_reward > 25 or episode_reward < 0:\n",
        "                epsilon = update_epsilon_nn(epsilon)\n",
        "                print(\"episode \", i)\n",
        "                print(\"episode cumulative reward: \", episode_reward)\n",
        "                print(\"current epsilon: \", epsilon)\n",
        "                print(\"#---------------------------------------------#\")\n",
        "                break\n",
        "\n",
        "            #Let's train the Neural Network every 4 actions and if the buffer has at least BATCH_SIZE elements\n",
        "            #if((len(buffer) >= config.BATCH_SIZE) and ((j+1) % 4 == 0)):\n",
        "            if(len(buffer) >= config.BATCH_SIZE):\n",
        "                batch = random.sample(buffer, config.BATCH_SIZE)\n",
        "\n",
        "                for current_frame, action, reward, next_frame, done in batch:\n",
        "\n",
        "                    # Find next best action using model network\n",
        "                    #next_frame = torch.from_numpy(next_frame.astype('float32')).to(config.DEVICE)\n",
        "                    #predictions_next = model(next_frame).detach().cpu().numpy()\n",
        "                    current_frame = torch.from_numpy(current_frame.astype('float32')).to(config.DEVICE)\n",
        "                    predictions_next = model(current_frame).detach().cpu().numpy()\n",
        "\n",
        "                    next_frame = torch.from_numpy(next_frame.astype('float32')).to(config.DEVICE)\n",
        "                    t = target_model(next_frame)\n",
        "                    predictions_next[action] = reward + config.GAMMA * max(t)\n",
        "\n",
        "                    #compute the predicted value of the model(output)\n",
        "                    output = model(current_frame)\n",
        "                    output =  output[..., np.newaxis]\n",
        "                    predictions_next =  predictions_next[..., np.newaxis]\n",
        "                    predictions_next = torch.from_numpy(predictions_next).to(config.DEVICE)\n",
        "                    #loss = huber_loss(output, predictions_next)\n",
        "                    loss = mean_squared_error(output, predictions_next)\n",
        "\n",
        "                    #Train network\n",
        "                    optimizer.zero_grad()#clear existing gradient\n",
        "                    loss.backward() #backpropagate the error\n",
        "                    optimizer.step() # update weights\n",
        "\n",
        "            time_frame_counter += 1\n",
        "\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            #save the weight of the network\n",
        "            config.save_model(model,optimizer,i+1)\n",
        "            torch.save({\n",
        "                \"state_dict\": model.state_dict(),\n",
        "                \"optimizer\": optimizer.state_dict(),\n",
        "            }, \"../drive/MyDrive/Checkpoint\")\n",
        "            print(\"Save weigths in: \"+ config.CHECKPOINT_FOLDER)\n",
        "\n",
        "        if (i+1) % 5 == 0:\n",
        "            #update weights of target network every 10 actions\n",
        "            print(\"Target network updated\")\n",
        "            config.load_model(config.CHECKPOINT_FOLDER,target_model,optimizer_target)\n",
        "\n",
        "\n",
        "        cum_reward_nn[i]=episode_reward\n",
        "        episode_reward = 0\n",
        "        tot_negative_reward = 1\n",
        "        time_frame_counter = 1\n",
        "\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTI2zOGcpXiu",
        "outputId": "89409c89-f675-43f5-96fd-02847b79c422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "episode  0\n",
            "episode cumulative reward:  -0.21622073578593437\n",
            "current epsilon:  0.99\n",
            "#---------------------------------------------#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCZDvbZaAKye"
      },
      "source": [
        "## Example"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}