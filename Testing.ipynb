{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Federico6419/MachineLearningProject/blob/main/Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4Mcql4zq7EK"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch import Tensor\n",
        "from collections import deque\n",
        "import config_test\n",
        "from model import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "#Average rewards\n",
        "average_random = np.zeros(config_test.NUM_EPISODES)\n",
        "average_QTable = np.zeros(config_test.NUM_EPISODES)\n",
        "average_nn = np.zeros(config_test.NUM_EPISODES)\n",
        "\n",
        "#Cumulative reward\n",
        "cum_reward_random = np.zeros(config_test.NUM_EPISODES)\n",
        "cum_reward_QTable = np.zeros(config_test.NUM_EPISODES)\n",
        "cum_reward_nn = np.zeros(config_test.NUM_EPISODES)\n",
        "\n",
        "#Action Space\n",
        "action_space = [\n",
        "                (-1, 1, 0.2), (0, 1, 0.2), (1, 1, 0.2),\n",
        "                (-1, 1,   0), (0, 1,   0), (1, 1,   0),\n",
        "                (-1, 0, 0.2), (0, 0, 0.2), (1, 0, 0.2),\n",
        "                (-1, 0,   0), (0, 0,   0), (1, 0,   0)\n",
        "              ]\n",
        "\n",
        "#This is the function that discretizes the image\n",
        "def discretize_image(image):\n",
        "    image = image.unsqueeze(0)\n",
        "\n",
        "    #Execute the 3x3 Average Pooling\n",
        "    pooling = nn.AvgPool2d(8, stride=8)\n",
        "    image = pooling(image)\n",
        "    image = image.squeeze(0)\n",
        "\n",
        "    #Create the image identifier\n",
        "    string = \"S\"\n",
        "    for i, x in enumerate(image.numpy()):\n",
        "        for j in x:\n",
        "            if(j < 30):\n",
        "                string = string + \"0\"\n",
        "            elif(j < 60):\n",
        "                string = string + \"1\"\n",
        "            elif(j < 90):\n",
        "                string = string + \"2\"\n",
        "            elif(j < 120):\n",
        "                string = string + \"3\"\n",
        "            elif(j < 150):\n",
        "                string = string + \"4\"\n",
        "            elif(j < 180):\n",
        "                string = string + \"5\"\n",
        "            elif(j < 210):\n",
        "                string = string + \"6\"\n",
        "            elif(j < 256):\n",
        "                string = string + \"7\"\n",
        "\n",
        "    return string\n",
        "\n",
        "\n",
        "#Initialize the Model and load weights\n",
        "model = Model().to(config_test.DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=config_test.LR)\n",
        "config_test.load_model(config_test.CHECKPOINT, model, optimizer)\n",
        "\n",
        "#Load the Q-Table csv file\n",
        "Q_Table = np.loadtxt('QTable.csv', delimiter=',')\n",
        "\n",
        "#Policies\n",
        "def policy(p, state):\n",
        "    if(p == \"Random\"):\n",
        "        return action_space[random.randrange(len(action_space))]          #Sample a random action from the Action Space\n",
        "\n",
        "    elif(p == \"Q-Table\"):\n",
        "        if state in Q_Table:\n",
        "            return action_space[np.argmax(Q_Table[state])]                #Return the action with the highest value for the current state in the Q-Table\n",
        "        else:\n",
        "            return (0, 1, 0)\n",
        "\n",
        "    elif(p == \"nn\"):\n",
        "        prediction = model(torch.from_numpy(state.astype('float32')).to(config_test.DEVICE)).detach().cpu().numpy()\n",
        "        action = action_space[np.argmax(prediction)]              #Select the action with the maximum predicted Q-Value\n",
        "        return action\n",
        "\n",
        "\n",
        "#Initialize the Car Racing Environment\n",
        "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
        "observation, info = env.reset()\n",
        "\n",
        "#Testing\n",
        "def test(strategy):\n",
        "    c_reward = 0                #Cumulative reward\n",
        "    total_reward = 0\n",
        "    episode = 0\n",
        "    for i in range(config_test.NUM_EPISODES):\n",
        "            observation, info = env.reset()\n",
        "\n",
        "            observation = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)           #Convert the state into a Grayscale Image, that is a Matrix 96x96 composed by Integer values\n",
        "\n",
        "            if(strategy == \"Neural Network policy\"):\n",
        "                frames_queue = deque([observation]*3, maxlen = 3)\n",
        "            elif(strategy == \"Q-Table policy\"):\n",
        "                #Discretize the image\n",
        "                observation = torch.from_numpy(observation.astype('float32'))\n",
        "                observation = discretize_image(observation)\n",
        "\n",
        "            for _ in range(250):\n",
        "                env.render()\n",
        "\n",
        "                if(strategy == \"Random policy\"):\n",
        "                    action = policy(\"Random\", observation)\n",
        "                elif(strategy == \"Q-Table policy\"):\n",
        "                    observation = discretize_image(observation)\n",
        "                    action = policy(\"Q-Table\", observation)\n",
        "                elif(strategy == \"Neural Network policy\"):\n",
        "                    current_frame = np.array(frames_queue)\n",
        "                    action = policy(\"nn\", current_frame)\n",
        "\n",
        "                observation, reward, done, truncated, info = env.step(action)\n",
        "                c_reward += reward\n",
        "\n",
        "                observation = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                if(strategy == \"Neural Network policy\"):\n",
        "                    frames_queue.append(observation)\n",
        "\n",
        "                if done or truncated:\n",
        "                    total_reward += c_reward\n",
        "                    break\n",
        "\n",
        "            if(strategy == \"random policy\"):\n",
        "                cum_reward_random[episode] = c_reward # save the cum_reward for the relative episode\n",
        "                average_random[episode]=total_reward/episode\n",
        "            elif(strategy == \"q table policy\"):\n",
        "                cum_reward_table[episode] = c_reward\n",
        "                average_table[episode]=total_reward/episode\n",
        "            elif(strategy == \"neural network policy\"):\n",
        "                cum_reward_nn[episode] = c_reward\n",
        "                average_nn[episode]=total_reward/episode\n",
        "\n",
        "            print(\"The cumulative reward is:\",c_reward)\n",
        "            c_reward = 0 # reset the current cumulative reward\n",
        "            print(\"Episode: \",episode)\n",
        "            episode += +1\n",
        "\n",
        "    print(f\"Tests for {strategy} finished after {config_test.NUM_EPISODES} episodes\")\n",
        "\n",
        "\n",
        "\n",
        "test(\"Random policy\")\n",
        "test(\"Q-Table policy\")\n",
        "test(\"Neural Network policy\")\n",
        "\n",
        "env.close()"
      ]
    }
  ]
}